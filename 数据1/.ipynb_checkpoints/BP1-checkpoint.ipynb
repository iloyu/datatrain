{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numsize=500#样本数\n",
    "feature=165 #特征数\n",
    "lrate=0.1 #学习速率\n",
    "batch_size = 100#训练batch的大小\n",
    "steps=10000#迭代次数\n",
    "dimension=165#维度\n",
    "total=400#训练样本数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX= pd.read_csv('xDataR1.txt',header=None,sep=',')\n",
    "inputY=pd.read_csv('yDataR1.txt',header=None,sep=',')\n",
    "\n",
    "x_data =inputX.values#[:,0:dimension]\n",
    "y_data=inputY.values#[:,0:dimension]\n",
    "\n",
    "\n",
    "train_start = 0\n",
    "train_end = int(np.floor(0.8*Numsize))\n",
    "test_start = train_end \n",
    "test_end = Numsize\n",
    "\n",
    "xdata_train = x_data[np.arange(train_start, train_end),:]\n",
    "xdata_test = x_data[np.arange(test_start, test_end), :]\n",
    "ydata_train =y_data[np.arange(train_start, train_end), :]\n",
    "ydata_test = y_data[np.arange(test_start, test_end), :]\n",
    "#归一化\n",
    "# xtrainMean=np.mean(xdata_train,axis=0)[:,newaxis]\n",
    "# xtrainStd=np.std(xdata_train,axis=0)[:,newaxis]\n",
    "# ytrainMean=np.mean(ydata_train,axis=0)[:,newaxis]\n",
    "# ytrainStd=np.std(ydata_train,axis=0)[:,newaxis]\n",
    "\n",
    "# xdata_train-=xtrainMean\n",
    "# xdata_train/=xtrainStd\n",
    "\n",
    "# xdata_test-=xtrainMean\n",
    "# xdata_test/=xtrainStd\n",
    "\n",
    "# ydata_train-=ytrainMean\n",
    "# ydata_train/=ytrainStd\n",
    "\n",
    "# ydata_test-=ytrainMean\n",
    "# ydata_test/=ytrainStd\n",
    "#转置\n",
    "# xdata_train = np.transpose(x_data[np.arange(train_start, train_end), :])\n",
    "# xdata_test = np.transpose(x_data[np.arange(test_start, test_end), :])\n",
    "# ydata_train =np.transpose(y_data[np.arange(train_start, train_end), :])\n",
    "# ydata_test = np.transpose(y_data[np.arange(test_start, test_end), :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 2.定义节点准备接收数据 \n",
    "# xs = tf.placeholder(tf.float32, [dimension,None]) \n",
    "# ys = tf.placeholder(tf.float32, [dimension,None]) \n",
    "# global_step=tf.Variable(0)\n",
    "# learning_rate=tf.train.exponential_decay(0.1,global_step,100,0.96,staircase=True)\n",
    "# learning_step=tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "xs = tf.placeholder(tf.float32, [None,dimension],name=\"x_traindata\") \n",
    "ys = tf.placeholder(tf.float32, [None,dimension],name=\"y_traindata\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(n_layer,inputs, in_size, out_size,Wname,Bname, activation_function):\n",
    "    # 构建权重 : in_size * out)_sieze 大小的矩阵\n",
    "    layer_name = 'layer%s'% n_layer\n",
    "    with tf.name_scope('layer_name'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            weights = tf.Variable(tf.truncated_normal([ in_size,out_size]),name=Wname)\n",
    "            # 构建偏置 : 1 * out_size 的矩阵\n",
    "            biases = tf.Variable(tf.constant(0.0, shape=[1,out_size], dtype=tf.float32),name=Bname)\n",
    "            # 矩阵相乘\n",
    "            Wx_plus_b =tf.add( tf.matmul(inputs,weights), biases)\n",
    "            if activation_function is None:\n",
    "                outputs = Wx_plus_b\n",
    "            else:\n",
    "                outputs = activation_function(Wx_plus_b)\n",
    "\n",
    "    return weights,outputs  # 得到输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hidden_layers1 =2048\n",
    "hidden_layers2=1024\n",
    "hidden_layers3=512\n",
    "hidden_layers4=256\n",
    "# 构建输入层到隐藏层,假设隐藏层有 hidden_layers 个神经元\n",
    "w1,h1 = add_layer(\"1\",xs, dimension, hidden_layers1,\"w1\",\"b1\",activation_function=tf.nn.relu)\n",
    "w2,h2 = add_layer(\"2\",h1, hidden_layers1, hidden_layers2,\"w2\",\"b2\", activation_function=tf.nn.relu)\n",
    "# w3,h3 = add_layer(\"3\",h2, hidden_layers2, hidden_layers3, \"w3\",\"b3\",activation_function=None)\n",
    "# w4,h4= add_layer(\"4\",h3, hidden_layers, hidden_layers,\"w4\",\"b4\", activation_function=tf.nn.tanh)\n",
    "# 构建隐藏层到输出层\n",
    "w5,prediction = add_layer(\"3\",h2, hidden_layers2 ,dimension,\"w3\",\"b3\", activation_function=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss =tf.reduce_mean(tf.abs(ys-prediction))#tf.losses.mean_squared_error(ys, prediction)#)#-tf.reduce_mean(ys*tf.log(tf.clip_by_value(prediction,1e-10,1)))#(tf.abs(tf.subtract(prediction,ys)))#reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n",
    "#loss=-tf.reduce_mean()\n",
    "train_step =tf.train.AdamOptimizer(lrate).minimize(loss)\n",
    "#tf.train.GradientDescentOptimizer(lrate).minimize(loss) # GradientDescentOptimizer 优化算法选取SGD,随机梯度下降\n",
    "\n",
    "# print('将计算图写入事件文件,在TensorBoard里查看')\n",
    "# writer = tf.summary.FileWriter(logdir='logs/8_2_BP', graph=tf.get_default_graph())\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78.634056\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "69.497246\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "61.372055\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "54.0837\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "47.571926\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "41.56975\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "35.969086\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "30.696444\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "25.796333\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "21.42431\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "17.387348\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "13.713593\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "10.604025\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "8.146407\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "6.5061836\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.7372017\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5344887\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.515054\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513688\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5135255\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134587\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513425\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134244\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513425\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513425\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134234\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134244\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513425\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134234\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513427\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513424\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513424\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134263\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134225\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513423\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134234\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513427\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134215\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513422\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134225\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513427\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134196\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134277\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134215\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134254\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513422\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134187\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134287\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134196\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513426\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134206\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513428\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513417\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513429\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134187\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513416\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.5134273\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "5.513415\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "predict1: [[ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]\n",
      " [ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]\n",
      " [ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]\n",
      " ...\n",
      " [ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]\n",
      " [ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]\n",
      " [ 122.34579  -148.77898    17.277613 ...   41.96031  -140.57126\n",
      "    35.06156 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.513415\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cost_history=[ ]\n",
    "saver = tf.train.Saver()\n",
    "test={xs: xdata_test, ys: ydata_test}\n",
    "train={xs: xdata_train, ys: ydata_train}\n",
    "sess=tf.Session() \n",
    "# 初始化所有变量\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "for i in range(1,steps+1):\n",
    "#     batchSize使用\n",
    "#     start=(i*batch_size)%total\n",
    "#     end=min(start+batch_size,total)\n",
    "#     if start==end:\n",
    "#         start=398\n",
    "#         end=399\n",
    "    sess.run(train_step, feed_dict=train)\n",
    "    if i % 100 == 0:\n",
    "#             m=(i)%100\n",
    "#             n=(i+1)%100\n",
    "#             if m>n:\n",
    "#                 m=n-1\n",
    "        cost=sess.run(loss, feed_dict=test)\n",
    "        print(cost)\n",
    "\n",
    "        hid1=sess.run(h1,feed_dict=test)\n",
    "        print(hid1)\n",
    "        predict=sess.run(prediction,feed_dict=test)\n",
    "\n",
    "#            print('prediction \\n',predict)\n",
    "        cost_history.append(cost) \n",
    "predict=sess.run(prediction,feed_dict={xs:xdata_test})\n",
    "#如果归一化了，结果得反归一predict=predict*ytrainStd+ytrainMean\n",
    "print(\"predict1:\",predict)\n",
    "error=predict-ydata_test\n",
    "np.savetxt('error.csv', error, delimiter = ',')\n",
    "saver.save(sess,\"./model.ckpt\")\n",
    "writer=tf.summary.FileWriter(\"./log\",tf.get_default_graph())\n",
    "writer.close()\n",
    "print(np.min(cost_history))\n",
    "  \n",
    "plt.plot ( range ( len ( cost_history ) ) ,cost_history )\n",
    "\n",
    "plt.axis ( [ 0,steps/100,0,100] )\n",
    "\n",
    "plt.xlabel ( 'training epochs' )\n",
    "\n",
    "plt.ylabel ( 'cost' )\n",
    "\n",
    "plt.title ( 'cost history' )\n",
    "\n",
    "plt.show ( ) \n",
    "# with tf.Session() as sess:\n",
    "#     saver.restore(sess,\"../model.ckpt\")\n",
    "    \n",
    "#     print(sess.run(prediction,feed_dict={xs:xdata_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([165,165]))\n",
    "b = tf.Variable(tf.zeros([1,165])+0.1)\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(xs,w),b))\n",
    "loss=tf.reduce_mean(tf.square(ys-prediction))\n",
    "train=tf.train.GradientDescentOptimizer(lrate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data=np.linspace(-1,1,165)[400]#[:,np.newaxis] #300*1,输入只有一个神经元\n",
    "#     X = tf.placeholder (tf.float32, shape = [None, input_size])\n",
    "#     Y = tf.placeholder (tf.float32, shape = [None, num_classes])import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "#     return tf.Variable(initial)\n",
    "# def bias_variable(shape):\n",
    "#     initial = tf.zeros(shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "# def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "#     Weights=weight_variable([in_size,out_size])\n",
    "#     biases=bias_variable([1,out_size])\n",
    "#     Wx_plus_b=tf.matmul(inputs,Weights)+biases\n",
    "#     if activation_function==None:\n",
    "#         outputs=Wx_plus_b\n",
    "#     else:\n",
    "#         outputs=activation_function(Wx_plus_b)\n",
    "#     return [outputs,Weights]\n",
    "\n",
    " # 3.定义神经层：隐藏层和预测层 \n",
    " \n",
    "h1=18\n",
    "h2=36\n",
    "h3=72\n",
    "l_1 = add_layer(xs,dimension,h1,activation_function = tf.nn.relu)\n",
    "# l_2=add_layer(l_1,h1,h2,activation_function = tf.nn.relu)\n",
    "prediction = add_layer(l_1,h1,dimension,activation_function = tf.nn.sigmoid)\n",
    "\n",
    "# l1 = add_layer(xs,dimension,h1,activation_function=tf.nn.relu) \n",
    "# # w2,l2=add_layer(l1,h1,h2,activation_function=tf.nn.relu)\n",
    "# # w3,l3=add_layer(l2,h2,h3,activation_function=tf.nn.relu)\n",
    "# prediction=add_layer (l1,h1,dimension,activation_function=tf.nn.relu) \n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1])) \n",
    "\n",
    "train_step =tf.train.GradientDescentOptimizer(lrate).minimize(loss)#tf.train.AdamOptimizer(lrate).minimize(loss) # \n",
    "# valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "# important step 对所有变量进行初始化 \n",
    "init = tf.global_variables_initializer()#tf.initialize_all_variables() \n",
    "sess = tf.Session() \n",
    "# 上面定义的都没有运算，直到 sess.run 才会开始运算 \n",
    "sess.run(init) \n",
    "# 迭代 1000 次学习，\n",
    "cost_history= [ ] \n",
    "for i in range(steps+1): \n",
    "\n",
    "    start = max((i * batch_size) % (Numsize),0)\n",
    "    end = min(start + batch_size,Numsize)\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data}) \n",
    "    if i % 50 == 0:\n",
    "# to see the step improvement\n",
    "        print ( \"After %d iteration:\" %i ) \n",
    "        cost=sess.run(loss, feed_dict={xs: x_data, ys: y_data})\n",
    "        print(cost)\n",
    "#         print(sess.run(w,feed_dict={xs: x_data, ys: y_data}))\n",
    "        cost_history.append (cost) \n",
    "saver = tf.train.Saver()\n",
    "# print(cost_history)\n",
    "plt.plot ( range ( len ( cost_history ) ) ,cost_history )\n",
    "\n",
    "plt.axis ( [ 0,10,0,np.max ( cost_history ) ] )\n",
    "\n",
    "plt.xlabel ( 'training epochs' )\n",
    "\n",
    "plt.ylabel ( 'cost' )\n",
    "\n",
    "plt.title ( 'cost history' )\n",
    "\n",
    "plt.show ( ) \n",
    "# init = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     save_path = saver.save(sess, \"my_net/save_net.ckpt\")\n",
    "#     print(\"Save to path: \", save_path)\n",
    "# pred_y = sess.run ( y, feed_dict={x: X_test} )\n",
    "\n",
    "# mse = tf.reduce_mean ( tf.square ( pred_y - y_test ) )\n",
    "\n",
    "# print ( \"MSE: %.4f\" % sess.run ( mse ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import numpy as np \n",
    "from numpy import *\n",
    "x_data=np.linspace(1,165)#reshape(400,165)#np.linspace(-1,1,165)\n",
    "x_data=mat(random.randint(50,200,size=(400,165)))\n",
    "# mnist = input_data.read_data_sets('data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(Numsize*feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data=mat(np.ones(Numsize*feature),size=(Numsize,feature))\n",
    "x_data=np.ones((total,feature))\n",
    "#x1=x1.reshape(Numsize,feature)\n",
    "print(x_data[400:500])\n",
    "# x_data=mat(random.randint(50,200,size=(Numsize,feature)))\n",
    "# noise=np.random.normal(0,0.05,x_data.shape)\n",
    "y_data=x_data*0.3+0.1#np.square(x_data)-0.5#+noise\n",
    "print(y_data)\n",
    "xs=tf.placeholder(tf.float32,[None,feature])\n",
    "ys=tf.placeholder(tf.float32,[None,feature])\n",
    "#定义隐含层\n",
    "# l1=add_layer(xs,165,165,activation_function=tf.nn.relu)\n",
    "# l2=add_layer(l1,165,165,activation_function=tf.nn.relu)\n",
    "\n",
    "#定义输出层,假设没有任何激活函数\n",
    "# [prediction,w]=add_layer(xs,165,165,activation_function=None)\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1),(165,1))\n",
    "biases = tf.Variable(tf.zeros([1]),(1,165))\n",
    "prediction = Weights*xs + biases\n",
    "loss=tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction)))#,reduction_indices=[1]\n",
    "optimizer=tf.train.GradientDescentOptimizer(lrate)\n",
    "train=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "\n",
    "#         print(start,end)\n",
    "        sess.run(train,feed_dict={xs:x_data,ys:y_data})\n",
    "        if i%100==0:\n",
    "            print(sess.run(loss,feed_dict={xs:x_data,ys:y_data}))\n",
    "            print(sess.run(Weights,feed_dict={xs:x_data,ys:y_data}))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for i in range(399):\n",
    "    plt.scatter(xdata_train[i,:],ydata_train[i,:],marker='o')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
