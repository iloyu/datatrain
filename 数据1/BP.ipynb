{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=500\n",
    "Numsize=500\n",
    "feature=165\n",
    "lrate=0.1\n",
    "batch_size = 1#训练batch的大小\n",
    "steps=20000\n",
    "dimension=165\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputX= pd.read_csv('xData.txt',header=None,sep=',')\n",
    "inputY=pd.read_csv('yData.txt',header=None,sep=',')\n",
    "\n",
    "x_data =inputX.values#[:,0:dimension]\n",
    "y_data=inputY.values#[:,0:dimension]\n",
    "#xmean=np.mean(x_data[:,0])\n",
    "#print(xmean)\n",
    "#print(x_data[:,0:3].shape)\n",
    "# print(y_data[:,0:3].shape)\n",
    "# noise = np.random.normal(0, 0.05, x_data.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # 2.定义节点准备接收数据 # define placeholder for inputs to network \n",
    "xs = tf.placeholder(tf.float32, [None ,dimension]) \n",
    "ys = tf.placeholder(tf.float32, [None,dimension]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_layer(inputs, in_size, out_size, activation_function=None): \n",
    "#     # add one more layer and return the output of this layer \n",
    "#     Weights = tf.Variable(tf.random_normal([in_size, out_size])) \n",
    "#     biases = tf.Variable(tf.zeros([1, out_size]) + 0.1) \n",
    "#     Wx_plus_b = tf.matmul(inputs, Weights) + biases \n",
    "#     if activation_function is None: \n",
    "#         outputs = Wx_plus_b\n",
    "#     else:\n",
    "#         outputs = activation_function(Wx_plus_b) \n",
    "#     return outputs\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    # 构建权重 : in_size * out)_sieze 大小的矩阵\n",
    "    weights = tf.Variable(tf.random_normal([ in_size,out_size]))\n",
    "    # 构建偏置 : 1 * out_size 的矩阵\n",
    "   # biases = tf.Variable(tf.zeros([in_size, out_size]) + 0.1)\n",
    "    # 矩阵相乘\n",
    "    Wx_plus_b = tf.matmul(inputs, weights) #+ biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "\n",
    "    return weights,outputs  # 得到输出数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def mean_squared_error(output, target, is_mean=False, name=\"mean_squared_error\"):\n",
    "#    with tf.name_scope(name):\n",
    "#        if output.get_shape().ndims == 2:  # [batch_size, n_feature]\n",
    "#            if is_mean:\n",
    "#                mse = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(output, target), 1))\n",
    "#            else:\n",
    "#                mse = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(output, target), 1))\n",
    "#        elif output.get_shape().ndims == 3:  # [batch_size, w, h]\n",
    "#            if is_mean:\n",
    "#                mse = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(output, target), [1, 2]))\n",
    "#            else:\n",
    "#                mse = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(output, target), [1, 2]))\n",
    "#        elif output.get_shape().ndims == 4:  # [batch_size, w, h, c]\n",
    "#            if is_mean:\n",
    "#                mse = tf.reduce_mean(tf.reduce_mean(tf.squared_difference(output, target), [1, 2, 3]))\n",
    "#            else:\n",
    "#                mse = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(output, target), [1, 2, 3]))\n",
    "#        else:\n",
    "#            raise Exception(\"Unknow dimension\")\n",
    "#        return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def sigmoid_cross_entropy(output, target, name=None):\n",
    "#    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output, name=name))\n",
    "#def normalized_mean_square_error(output, target):\n",
    "#    with tf.name_scope(\"mean_squared_error_loss\"):\n",
    "#        if output.get_shape().ndims == 2:  # [batch_size, n_feature]\n",
    "#            nmse_a = tf.sqrt(tf.reduce_sum(tf.squared_difference(output, target), axis=1))\n",
    "#            nmse_b = tf.sqrt(tf.reduce_sum(tf.square(target), axis=1))\n",
    "#        elif output.get_shape().ndims == 3:  # [batch_size, w, h]\n",
    "#            nmse_a = tf.sqrt(tf.reduce_sum(tf.squared_difference(output, target), axis=[1, 2]))\n",
    "#            nmse_b = tf.sqrt(tf.reduce_sum(tf.square(target), axis=[1, 2]))\n",
    "#        elif output.get_shape().ndims == 4:  # [batch_size, w, h, c]\n",
    "#            nmse_a = tf.sqrt(tf.reduce_sum(tf.squared_difference(output, target), axis=[1, 2, 3]))\n",
    "#            nmse_b = tf.sqrt(tf.reduce_sum(tf.square(target), axis=[1, 2, 3]))\n",
    "#        nmse = tf.reduce_mean(nmse_a / nmse_b)\n",
    "#    return nmse\n",
    "#def absolute_difference_error(output, target, is_mean=False):\n",
    "#    with tf.name_scope(\"mean_squared_error_loss\"):\n",
    "#        if output.get_shape().ndims == 2:  # [batch_size, n_feature]\n",
    "#            if is_mean:\n",
    "#                loss = tf.reduce_mean(tf.reduce_mean(tf.abs(output - target), 1))\n",
    "#            else:\n",
    "#                loss = tf.reduce_mean(tf.reduce_sum(tf.abs(output - target), 1))\n",
    "#        elif output.get_shape().ndims == 3:  # [batch_size, w, h]\n",
    "#            if is_mean:\n",
    "#                loss = tf.reduce_mean(tf.reduce_mean(tf.abs(output - target), [1, 2]))\n",
    "#            else:\n",
    "#                loss = tf.reduce_mean(tf.reduce_sum(tf.abs(output - target), [1, 2]))\n",
    "#        elif output.get_shape().ndims == 4:  # [batch_size, w, h, c]\n",
    "#            if is_mean:\n",
    "#                loss = tf.reduce_mean(tf.reduce_mean(tf.abs(output - target), [1, 2, 3]))\n",
    "#            else:\n",
    "#                loss = tf.reduce_mean(tf.reduce_sum(tf.abs(output - target), [1, 2, 3]))\n",
    "#        else:\n",
    "#            raise Exception(\"Unknow dimension\")\n",
    "#        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = 165\n",
    "# 构建输入层到隐藏层,假设隐藏层有 hidden_layers 个神经元\n",
    "w1,h1 = add_layer(xs, dimension, hidden_layers, activation_function=tf.nn.sigmoid)\n",
    "# 构建隐藏层到隐藏层\n",
    "w2,h2 = add_layer(h1, hidden_layers, hidden_layers, activation_function=tf.nn.sigmoid)\n",
    "w3,h3 = add_layer(h2, hidden_layers, hidden_layers, activation_function=tf.nn.sigmoid)\n",
    "# 构建隐藏层到隐藏层\n",
    "w4,h4= add_layer(h3, hidden_layers, hidden_layers, activation_function=tf.nn.relu)\n",
    "# 构建隐藏层到输出层\n",
    "w5,prediction = add_layer(h1, hidden_layers, dimension, activation_function=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.square(prediction-ys))))#reduce_sum(tf.square(ys - prediction), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(lrate).minimize(loss) # 优化算法选取SGD,随机梯度下降\n",
    "\n",
    "# print('将计算图写入事件文件,在TensorBoard里查看')\n",
    "# writer = tf.summary.FileWriter(logdir='logs/8_2_BP', graph=tf.get_default_graph())\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-487af5b47a6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#x_test=x_data[1,:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 初始化所有变量\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, feed_dict, session)\u001b[0m\n\u001b[1;32m   2397\u001b[0m         \u001b[0mnone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0msession\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m     \"\"\"\n\u001b[0;32m-> 2399\u001b[0;31m     \u001b[0m_run_using_default_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m \u001b[0m_gradient_registry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRegistry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gradient\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_run_using_default_session\u001b[0;34m(operation, feed_dict, graph, session)\u001b[0m\n\u001b[1;32m   5246\u001b[0m                        \u001b[0;34m\"the operation's graph is different from the session's \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5247\u001b[0m                        \"graph.\")\n\u001b[0;32m-> 5248\u001b[0;31m   \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "cost_history=[ ]\n",
    "#x_test=x_data[1,:]\n",
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()  # 初始化所有变量\n",
    " \n",
    "    for i in range(steps+1):\n",
    "       \n",
    "        start=(i*batch_size)%total\n",
    "        end=min(start+batch_size,total)\n",
    "        sess.run(train_step, feed_dict={xs: x_data[start:end], ys: y_data[start:end]})\n",
    "#         print(xs)\n",
    "        if i % 10 == 0:\n",
    "            cost=sess.run(loss, feed_dict={xs: x_data, ys: y_data})\n",
    "            #print('w1',sess.run(w1,feed_dict={xs:x_data}))\n",
    "#             print('第%d次的损失值为'%i,cost)\n",
    "#             print(xs)\n",
    "         #   print('h1:',sess.run(h1,feed_dict={xs:x_data}))\n",
    "#             print('h2:',sess.run(w2,feed_dict={xs:h1}))\n",
    "#             print('第%d次的损失值为'%i,cost)\n",
    "#             print(xs)\n",
    "            #print('prediction',sess.run(prediction,feed_dict={xs:x_test}))\n",
    "            cost_history.append (cost) \n",
    "saver = tf.train.Saver()\n",
    "print(np.min(cost_history))\n",
    "plt.plot ( range ( len ( cost_history ) ) ,cost_history )\n",
    "\n",
    "plt.axis ( [ 0,1000,0,np.max ( cost_history ) ] )\n",
    "\n",
    "plt.xlabel ( 'training epochs' )\n",
    "\n",
    "plt.ylabel ( 'cost' )\n",
    "\n",
    "plt.title ( 'cost history' )\n",
    "\n",
    "plt.show ( ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = tf.Variable(tf.random_normal([165,165]))\n",
    "b = tf.Variable(tf.zeros([1,165])+0.1)\n",
    "prediction = tf.nn.softmax(tf.add(tf.matmul(xs,w),b))\n",
    "loss=tf.reduce_mean(tf.square(ys-prediction))\n",
    "train=tf.train.GradientDescentOptimizer(lrate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data=np.linspace(-1,1,165)[400]#[:,np.newaxis] #300*1,输入只有一个神经元\n",
    "#     X = tf.placeholder (tf.float32, shape = [None, input_size])\n",
    "#     Y = tf.placeholder (tf.float32, shape = [None, num_classes])import tensorflow as tf\n",
    "\n",
    "\n",
    "\n",
    "# def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "#     return tf.Variable(initial)\n",
    "# def bias_variable(shape):\n",
    "#     initial = tf.zeros(shape)\n",
    "#     return tf.Variable(initial)\n",
    "\n",
    "# def add_layer(inputs,in_size,out_size,activation_function=None):\n",
    "#     Weights=weight_variable([in_size,out_size])\n",
    "#     biases=bias_variable([1,out_size])\n",
    "#     Wx_plus_b=tf.matmul(inputs,Weights)+biases\n",
    "#     if activation_function==None:\n",
    "#         outputs=Wx_plus_b\n",
    "#     else:\n",
    "#         outputs=activation_function(Wx_plus_b)\n",
    "#     return [outputs,Weights]\n",
    "\n",
    " # 3.定义神经层：隐藏层和预测层 \n",
    " \n",
    "h1=18\n",
    "h2=36\n",
    "h3=72\n",
    "l_1 = add_layer(xs,dimension,h1,activation_function = tf.nn.relu)\n",
    "# l_2=add_layer(l_1,h1,h2,activation_function = tf.nn.relu)\n",
    "prediction = add_layer(l_1,h1,dimension,activation_function = tf.nn.sigmoid)\n",
    "\n",
    "# l1 = add_layer(xs,dimension,h1,activation_function=tf.nn.relu) \n",
    "# # w2,l2=add_layer(l1,h1,h2,activation_function=tf.nn.relu)\n",
    "# # w3,l3=add_layer(l2,h2,h3,activation_function=tf.nn.relu)\n",
    "# prediction=add_layer (l1,h1,dimension,activation_function=tf.nn.relu) \n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction), reduction_indices=[1])) \n",
    "\n",
    "train_step =tf.train.GradientDescentOptimizer(lrate).minimize(loss)#tf.train.AdamOptimizer(lrate).minimize(loss) # \n",
    "# valid_prediction = tf.nn.softmax(tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "# important step 对所有变量进行初始化 \n",
    "init = tf.global_variables_initializer()#tf.initialize_all_variables() \n",
    "sess = tf.Session() \n",
    "# 上面定义的都没有运算，直到 sess.run 才会开始运算 \n",
    "sess.run(init) \n",
    "# 迭代 1000 次学习，\n",
    "cost_history= [ ] \n",
    "for i in range(steps+1): \n",
    "\n",
    "    start = max((i * batch_size) % (Numsize),0)\n",
    "    end = min(start + batch_size,Numsize)\n",
    "    sess.run(train_step, feed_dict={xs: x_data, ys: y_data}) \n",
    "    if i % 50 == 0:\n",
    "# to see the step improvement\n",
    "        print ( \"After %d iteration:\" %i ) \n",
    "        cost=sess.run(loss, feed_dict={xs: x_data, ys: y_data})\n",
    "        print(cost)\n",
    "#         print(sess.run(w,feed_dict={xs: x_data, ys: y_data}))\n",
    "        cost_history.append (cost) \n",
    "saver = tf.train.Saver()\n",
    "# print(cost_history)\n",
    "plt.plot ( range ( len ( cost_history ) ) ,cost_history )\n",
    "\n",
    "plt.axis ( [ 0,10,0,np.max ( cost_history ) ] )\n",
    "\n",
    "plt.xlabel ( 'training epochs' )\n",
    "\n",
    "plt.ylabel ( 'cost' )\n",
    "\n",
    "plt.title ( 'cost history' )\n",
    "\n",
    "plt.show ( ) \n",
    "# init = tf.global_variables_initializer()\n",
    "# with tf.Session() as sess:\n",
    "#     sess.run(init)\n",
    "#     save_path = saver.save(sess, \"my_net/save_net.ckpt\")\n",
    "#     print(\"Save to path: \", save_path)\n",
    "# pred_y = sess.run ( y, feed_dict={x: X_test} )\n",
    "\n",
    "# mse = tf.reduce_mean ( tf.square ( pred_y - y_test ) )\n",
    "\n",
    "# print ( \"MSE: %.4f\" % sess.run ( mse ) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf \n",
    "# from  tensorflow.examples.tutorials.mnist  import  input_data\n",
    "import numpy as np \n",
    "from numpy import *\n",
    "x_data=np.linspace(1,165)#reshape(400,165)#np.linspace(-1,1,165)\n",
    "x_data=mat(random.randint(50,200,size=(400,165)))\n",
    "# mnist = input_data.read_data_sets('data', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(Numsize*feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_data=mat(np.ones(Numsize*feature),size=(Numsize,feature))\n",
    "x_data=np.ones((total,feature))\n",
    "#x1=x1.reshape(Numsize,feature)\n",
    "print(x_data[400:500])\n",
    "# x_data=mat(random.randint(50,200,size=(Numsize,feature)))\n",
    "# noise=np.random.normal(0,0.05,x_data.shape)\n",
    "y_data=x_data*0.3+0.1#np.square(x_data)-0.5#+noise\n",
    "print(y_data)\n",
    "xs=tf.placeholder(tf.float32,[None,feature])\n",
    "ys=tf.placeholder(tf.float32,[None,feature])\n",
    "#定义隐含层\n",
    "# l1=add_layer(xs,165,165,activation_function=tf.nn.relu)\n",
    "# l2=add_layer(l1,165,165,activation_function=tf.nn.relu)\n",
    "\n",
    "#定义输出层,假设没有任何激活函数\n",
    "# [prediction,w]=add_layer(xs,165,165,activation_function=None)\n",
    "Weights = tf.Variable(tf.random_uniform([1], -1.0, 1),(165,1))\n",
    "biases = tf.Variable(tf.zeros([1]),(1,165))\n",
    "prediction = Weights*xs + biases\n",
    "loss=tf.reduce_mean(tf.reduce_sum(tf.square(ys-prediction)))#,reduction_indices=[1]\n",
    "optimizer=tf.train.GradientDescentOptimizer(lrate)\n",
    "train=optimizer.minimize(loss)\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(steps):\n",
    "\n",
    "#         print(start,end)\n",
    "        sess.run(train,feed_dict={xs:x_data,ys:y_data})\n",
    "        if i%100==0:\n",
    "            print(sess.run(loss,feed_dict={xs:x_data,ys:y_data}))\n",
    "            print(sess.run(Weights,feed_dict={xs:x_data,ys:y_data}))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
